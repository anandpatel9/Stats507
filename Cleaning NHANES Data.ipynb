{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats 507 - HW 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1: Using Git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data_2012 = pd.read_sas('Demo_G.XPT')\n",
    "demo_data_2012['cohort'] = [2012 for i in range(demo_data_2012.shape[0])]\n",
    "\n",
    "demo_data_2014 = pd.read_sas('Demo_H.XPT')\n",
    "demo_data_2014['cohort'] = [2014 for i in range(demo_data_2014.shape[0])]\n",
    "\n",
    "demo_data_2016 = pd.read_sas('Demo_I.XPT')\n",
    "demo_data_2016['cohort'] = [2016 for i in range(demo_data_2016.shape[0])]\n",
    "\n",
    "demo_data_2018 = pd.read_sas('Demo_J.XPT')\n",
    "demo_data_2018['cohort'] = [2018 for i in range(demo_data_2018.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_data = pd.DataFrame()\n",
    "for i in [demo_data_2012,\n",
    "          demo_data_2014,\n",
    "          demo_data_2016,\n",
    "          demo_data_2018]:\n",
    "    subset_data = subset_data.append(i)\n",
    "\n",
    "deom_subset_data = subset_data[['cohort',\n",
    "                                'SEQN',\n",
    "                                'RIAGENDR',\n",
    "                                'RIDAGEYR',\n",
    "                                'RIDRETH3',\n",
    "                                'DMDEDUC2',\n",
    "                                'DMDMARTL',\n",
    "                                'RIDSTATR',\n",
    "                                'SDMVPSU',\n",
    "                                'SDMVSTRA',\n",
    "                                'WTMEC2YR',\n",
    "                                'WTINT2YR']]\n",
    "\n",
    "demographic_data = deom_subset_data.drop_duplicates(\n",
    "    subset = 'SEQN').copy()\n",
    "\n",
    "demographic_data = demographic_data.rename(\n",
    "    {'SEQN':'ids',\n",
    "     'RIDAGEYR': 'age',\n",
    "     'RIAGENDR': 'gender',\n",
    "     'RIDRETH3': 'race and ethnicity',\n",
    "     'DMDEDUC2': 'education',\n",
    "     'DMDMARTL': 'marital status',\n",
    "     'RIDSTATR': 'examination status',\n",
    "     'SDMVPSU': 'pseudo psu variance',\n",
    "     'SDMVSTRA': 'pseudo stratum variance',\n",
    "     'WTMEC2YR': 'full 2 year mec exam weight',\n",
    "     'WTINT2YR' : 'full 2 year mec interview weight'},\n",
    "    axis = 1)\n",
    "\n",
    "demographic_data_2 = demographic_data.fillna(-1).copy()\n",
    "\n",
    "demographic_data_2 = demographic_data_2.astype(\n",
    "    {'age': 'int',\n",
    "     'gender': 'category',\n",
    "     'race and ethnicity': 'int',\n",
    "     'marital status': 'int',\n",
    "     'education': 'int',\n",
    "     'age': 'int',\n",
    "     'ids': 'int',\n",
    "     'examination status':'int'\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_data_2['education level'] = pd.Categorical(\n",
    "    demographic_data_2['education'].replace(\n",
    "        {1 : 'Less than 9th Grade',\n",
    "         2: '9 - 11 Grade - No Diploma',\n",
    "         3: 'High School Graduate/GED',\n",
    "         4: 'Some College',\n",
    "         5: 'College Graduate',\n",
    "         7: 'Refused',\n",
    "         9: 'Do not know',\n",
    "         -1: 'Missing'}))\n",
    "demographic_data_2['marital status 2'] = pd.Categorical(\n",
    "    demographic_data_2['marital status'].replace(\n",
    "        {1: 'Married',\n",
    "         2: 'Widowed',\n",
    "         3: 'Divorced',\n",
    "         4: 'Separated',\n",
    "         5: 'Never Married',\n",
    "         6: 'Living with Partner',\n",
    "         77: 'Refused',\n",
    "         99: 'Do not know',\n",
    "         -1 : 'Missing'}))\n",
    "                                                  \n",
    "demographic_data_2['race and ethnicity 2'] = pd.Categorical(\n",
    "    demographic_data_2['race and ethnicity'].replace(\n",
    "        {1: 'Mexican American',\n",
    "         2: 'Other Hispanic',\n",
    "         3: 'Non Hispanic White',\n",
    "         4: 'Non Hispanic Black',\n",
    "         6: 'Non Hispanic Asian',\n",
    "         7: 'Other',\n",
    "         -1: 'Missing'}))\n",
    "demographic_data_2['examination status 2'] = pd.Categorical(\n",
    "    demographic_data_2['examination status'].replace(\n",
    "        {1: 'Interview Only',\n",
    "         2: 'Interview and MEC',\n",
    "         -1: 'Missing'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_data_2.to_pickle('./cleaned_demo_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Part B*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oral_2012 = pd.read_sas('OHXDEN_G.XPT')\n",
    "oral_2014 = pd.read_sas('OHXDEN_H.XPT')\n",
    "oral_2016 = pd.read_sas('OHXDEN_I.XPT')\n",
    "oral_2018 = pd.read_sas('OHXDEN_J.XPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_2012 = pd.Series([2012 for i in range(oral_2012.shape[0])])\n",
    "\n",
    "oral_2012_cohorts = pd.concat(\n",
    "    (oral_2012, c_2012.rename('cohort')), axis = 1).copy()\n",
    "\n",
    "c_2014 = pd.Series(\n",
    "    [2014 for i in range(oral_2014.shape[0])])\n",
    "\n",
    "oral_2014_cohorts = pd.concat(\n",
    "    (oral_2014, c_2014.rename('cohort')), axis = 1).copy()\n",
    "\n",
    "c_2016 = pd.Series(\n",
    "    [2016 for i in range(oral_2016.shape[0])])\n",
    "\n",
    "oral_2016_cohorts = pd.concat(\n",
    "    (oral_2016, c_2016.rename('cohort')), axis = 1).copy()\n",
    "\n",
    "c_2018 = pd.Series(\n",
    "    [2018 for i in range(oral_2018.shape[0])])\n",
    "\n",
    "oral_2018_cohorts = pd.concat(\n",
    "    (oral_2018, c_2018.rename('cohort')), axis = 1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_oral_data = pd.concat((oral_2012_cohorts,\n",
    "                          oral_2014_cohorts,\n",
    "                          oral_2016_cohorts,\n",
    "                          oral_2018_cohorts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oral_subsetted_data= all_oral_data.filter(\n",
    "    regex = r'(SEQN|cohort|OHDDESTS|OHX.*TC)').rename(\n",
    "    {'SEQN': 'ids',\n",
    "     'OHDDESTS': 'dentation status code'},\n",
    "    axis = 1).apply(\n",
    "    lambda x: x.astype('category')).astype(\n",
    "    {'ids': int}).copy()\n",
    "\n",
    "col_names = dict()\n",
    "tooth_keys = range(1,33)\n",
    "for i in tooth_keys:\n",
    "    if i < 10:\n",
    "        col_names['OHX0' + str(i) +'TC'] = 'Tooth Count ' + str(i)\n",
    "        col_names['OHX0' + str(i) + 'CTC'] = 'Coronal Count ' + str(i)\n",
    "        col_names['OHX0' + str(i) + 'RTC'] = 'Coronal Second Restoration ' + str(i)\n",
    "    else:\n",
    "        col_names['OHX' + str(i) + 'TC'] = 'Tooth Count ' + str(i)\n",
    "        col_names['OHX' + str(i) + 'CTC'] = 'Coronal Count ' + str(i)\n",
    "        col_names['OHX' + str(i) + 'RTC'] = 'Coronal Second Restoration ' + str(i)\n",
    "        \n",
    "oral_subsetted_data = oral_subsetted_data.rename(columns = col_names)\n",
    "\n",
    "oral_subsetted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oral_subsetted_data.to_pickle('./cleaned_oral_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Part C* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(demographic_data_2,\n",
    "                   oral_subsetted_data,\n",
    "                   how='inner',\n",
    "                   left_on='ids',\n",
    "                   right_on='ids')\n",
    "counts = {'Joint': merged_df.shape[0], \n",
    "          'Demographic Data': demographic_data_2.shape[0], \n",
    "          'Oral Data': oral_subsetted_data.shape[0]}\n",
    "\n",
    "counts_df = pd.DataFrame(counts, index = ['Counts'])\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML, Markdown\n",
    "display(HTML(counts_df.to_html(index=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_pickle('./merged_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
